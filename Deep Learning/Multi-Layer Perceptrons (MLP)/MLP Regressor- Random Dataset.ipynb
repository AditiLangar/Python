{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am generating a random dataset in this file just to see how the MLP Regressor works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Random Data\n",
    "\n",
    "X_train = [[22,33],\n",
    "           [44,55]]\n",
    "\n",
    "y_train = [22,34]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = MLPRegressor(hidden_layer_sizes=(2,3),verbose=2,activation=\"relu\" ,\n",
    "                   batch_size=40,random_state=1, max_iter=2000, learning_rate_init=0.03)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aditi\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:353: UserWarning: Got `batch_size` less than 1 or larger than sample size. It is going to be clipped\n",
      "  warnings.warn(\"Got `batch_size` less than 1 or larger than \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 439.91277618\n",
      "Iteration 2, loss = 438.17080075\n",
      "Iteration 3, loss = 436.48627815\n",
      "Iteration 4, loss = 434.85949119\n",
      "Iteration 5, loss = 433.29007947\n",
      "Iteration 6, loss = 431.77675946\n",
      "Iteration 7, loss = 430.31693847\n",
      "Iteration 8, loss = 428.90622148\n",
      "Iteration 9, loss = 427.53787313\n",
      "Iteration 10, loss = 426.20241648\n",
      "Iteration 11, loss = 424.88768064\n",
      "Iteration 12, loss = 423.57958647\n",
      "Iteration 13, loss = 422.26361699\n",
      "Iteration 14, loss = 420.92642523\n",
      "Iteration 15, loss = 419.52103039\n",
      "Iteration 16, loss = 417.64031843\n",
      "Iteration 17, loss = 414.91432690\n",
      "Iteration 18, loss = 411.11946441\n",
      "Iteration 19, loss = 405.83735805\n",
      "Iteration 20, loss = 398.59220824\n",
      "Iteration 21, loss = 388.88394456\n",
      "Iteration 22, loss = 376.21225785\n",
      "Iteration 23, loss = 360.09838715\n",
      "Iteration 24, loss = 340.10889393\n",
      "Iteration 25, loss = 315.89219893\n",
      "Iteration 26, loss = 287.23422082\n",
      "Iteration 27, loss = 254.13606462\n",
      "Iteration 28, loss = 216.91697632\n",
      "Iteration 29, loss = 176.34701980\n",
      "Iteration 30, loss = 133.81386686\n",
      "Iteration 31, loss = 91.52332767\n",
      "Iteration 32, loss = 52.71323587\n",
      "Iteration 33, loss = 21.79072345\n",
      "Iteration 34, loss = 4.08172147\n",
      "Iteration 35, loss = 4.30281533\n",
      "Iteration 36, loss = 22.25782366\n",
      "Iteration 37, loss = 47.65669113\n",
      "Iteration 38, loss = 64.42023889\n",
      "Iteration 39, loss = 64.95149237\n",
      "Iteration 40, loss = 52.13195587\n",
      "Iteration 41, loss = 33.37578134\n",
      "Iteration 42, loss = 15.90360071\n",
      "Iteration 43, loss = 4.64800024\n",
      "Iteration 44, loss = 1.65401611\n",
      "Iteration 45, loss = 5.92982878\n",
      "Iteration 46, loss = 13.22131941\n",
      "Iteration 47, loss = 18.51365095\n",
      "Iteration 48, loss = 19.64237678\n",
      "Iteration 49, loss = 16.95494363\n",
      "Iteration 50, loss = 11.95418837\n",
      "Iteration 51, loss = 6.55702785\n",
      "Iteration 52, loss = 2.67352482\n",
      "Iteration 53, loss = 1.80496353\n",
      "Iteration 54, loss = 4.07224962\n",
      "Iteration 55, loss = 6.73959792\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPRegressor(batch_size=40, hidden_layer_sizes=(2, 3), learning_rate_init=0.03,\n",
       "             max_iter=2000, random_state=1, verbose=2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test =[[22,33],\n",
    "           [44,55]]\n",
    "\n",
    "y_test= [22,33]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([21.97003844, 39.37681381])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7315827599624313"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "r2_score(y_pred, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
